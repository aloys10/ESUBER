#!/usr/bin/env python3
"""
DeepSeekå®éªŒè¿è¡Œè„šæœ¬
ä¸“é—¨ç”¨äºè¿è¡Œä½¿ç”¨DeepSeekæ¨¡å‹çš„ä¹¦ç±æ¨èç³»ç»Ÿå®éªŒ
"""

import os
import argparse
import sys

# æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®
def check_environment():
    """æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡æ˜¯å¦å·²è®¾ç½®"""
    api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½®DeepSeek APIå¯†é’¥")
        print("è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€:")
        print("  - DEEPSEEK_API_KEY: DeepSeekä¸“ç”¨APIå¯†é’¥")
        print("  - OPENAI_API_KEY: OpenAIå…¼å®¹çš„APIå¯†é’¥")
        print("\nè®¾ç½®æ–¹æ³•:")
        print("  Windows PowerShell:")
        print("    $env:DEEPSEEK_API_KEY='your_api_key_here'")
        print("  Windows CMD:")
        print("    set DEEPSEEK_API_KEY=your_api_key_here")
        print("  Linux/Mac:")
        print("    export DEEPSEEK_API_KEY=your_api_key_here")
        return False
    
    print("âœ… DeepSeek APIå¯†é’¥å·²è®¾ç½®")
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è¿è¡ŒDeepSeekä¹¦ç±æ¨èç³»ç»Ÿå®éªŒ")
    parser.add_argument("--skip-sampling", action="store_true", default=False, 
                       help="è·³è¿‡é‡‡æ ·ç ”ç©¶")
    
    parser.add_argument("--llm-rater", type=str, default="0Shot_cotlite_our",
                       choices=["2Shot_system_our", "1Shot_system_our", "0Shot_system_our", 
                               "0Shot_cotlite_our", "2Shot_system_default", "1Shot_system_default", 
                               "0Shot_system_default",
                               # æ–°å¢çš„é€»è¾‘é“¾å¢å¼ºç‰ˆæœ¬
                               "2Shot_cot_enhanced", "1Shot_cot_enhanced", "0Shot_cot_enhanced"],
                       help="LLMè¯„åˆ†å™¨ç±»å‹")
    parser.add_argument("--items-retrieval", type=str, default="decay_emotion_3",
                       choices=["last_3", "most_similar_3", "none", "simple_3", "decay_emotion_3"],
                       help="ç‰©å“æ£€ç´¢ç­–ç•¥")
    parser.add_argument("--user-dataset", type=str, default="detailed",
                       choices=["detailed", "sampled"],
                       help="ç”¨æˆ·æ•°æ®é›†ç±»å‹")
    parser.add_argument("--perturbator", type=str, default="none",
                       choices=["none", "gaussian", "greedy"],
                       help="å¥–åŠ±æ‰°åŠ¨å™¨ç±»å‹")
    parser.add_argument("--show-prompt", action="store_true", default=False,
                       help="æ˜¾ç¤ºå®Œæ•´çš„LLM promptå†…å®¹")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not check_environment():
        sys.exit(1)
    
    print("ğŸš€ å¼€å§‹è¿è¡ŒDeepSeekå®éªŒ...")
    print(f"ğŸ“Š å®éªŒé…ç½®:")
    print(f"  - è¯„åˆ†å™¨: {args.llm_rater}")
    print(f"  - æ£€ç´¢ç­–ç•¥: {args.items_retrieval}")
    print(f"  - ç”¨æˆ·æ•°æ®é›†: {args.user_dataset}")
    print(f"  - æ‰°åŠ¨å™¨: {args.perturbator}")
    print(f"  - è·³è¿‡é‡‡æ ·: {args.skip_sampling}")
    print(f"  - æ˜¾ç¤ºPrompt: {args.show_prompt}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["LLM_MODEL"] = "deepseek-chat"
    
    # ç›´æ¥è¿è¡Œå®éªŒï¼Œè€Œä¸æ˜¯å°è¯•å¯¼å…¥
    try:
        print("\nğŸ”¬ æ­£åœ¨è¿è¡Œå®éªŒ...")
        
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        project_root = os.path.join(os.path.dirname(__file__), '..', '..')
        sys.path.insert(0, os.path.abspath(project_root))
        
        # ç›´æ¥å¯¼å…¥å¹¶è¿è¡Œå®éªŒ
        from environment.books.books_loader import BooksLoader
        from ablations.books.src import (
            CategoryPreferenceStudy,
            HighRatingStudy,
            LowRatingStudy,
            BooksCollectionStudy,
            SamplingSubsetInteractionsStudy
        )
        from environment.LLM import load_LLM
        from environment.env import Simulatio4RecSys
        from environment.items_selection import GreedySelector
        from environment.reward_shaping import IdentityRewardShaping
        from environment.users import UsersLoader
        from environment.books.configs import (
            get_llm_rater,
            get_reward_perturbator,
            get_items_retrieval,
            get_user_dataset,
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = load_LLM("deepseek-chat")
        
        # åˆ›å»ºç¯å¢ƒå‡½æ•°
        def create_env(item: str, user_loader_param):
            # å¦‚æœuser_loader_paramæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™åˆ›å»ºç›¸åº”çš„ç”¨æˆ·åŠ è½½å™¨
            if isinstance(user_loader_param, str):
                if user_loader_param == "detailed":
                    from environment.users import UsersCSVLoader
                    users_loader = UsersCSVLoader("users_600", os.path.join(os.path.dirname(__file__), "..", "..", "environment/books/users_generation/datasets/"))
                elif user_loader_param == "sampled":
                    from environment.users import UsersCSVLoader
                    users_loader = UsersCSVLoader("users_600_sampled", os.path.join(os.path.dirname(__file__), "..", "..", "environment/books/users_generation/datasets/"))
                else:
                    # é»˜è®¤ä½¿ç”¨detailed
                    from environment.users import UsersCSVLoader
                    users_loader = UsersCSVLoader("users_600", os.path.join(os.path.dirname(__file__), "..", "..", "environment/books/users_generation/datasets/"))
            else:
                users_loader = user_loader_param
            
            return Simulatio4RecSys(
                render_mode=None,
                items_loader=BooksLoader(item),
                users_loader=users_loader,
                items_selector=GreedySelector(),
                reward_perturbator=get_reward_perturbator(args.perturbator, seed=42),
                items_retrieval=get_items_retrieval(args.items_retrieval, args),
                llm_rater=get_llm_rater(
                    args.llm_rater, model, args.items_retrieval != "none", args.show_prompt
                ),
                reward_shaping=IdentityRewardShaping(seed=42),
            )
        
        # è®¾ç½®å®éªŒåç§°
        exp_name = f"deepseek-chat-{args.llm_rater}-{args.perturbator}-{args.items_retrieval}"
        if args.user_dataset == "users_600_basic":
            exp_name += "-basic_users"
        
        print(f"ğŸš€ [å®éªŒ] å¼€å§‹è¿è¡Œå®éªŒ: {exp_name}")
        
        # 1. è¿è¡Œç±»åˆ«åå¥½ç ”ç©¶å®éªŒï¼ˆè·³è¿‡ï¼Œå› ä¸ºå·²ç»è¿è¡Œè¿‡äº†ï¼‰
        genre_study = CategoryPreferenceStudy(create_env, exp_name)
        genre_study.run()

        
        # 2. è¿è¡Œé«˜åˆ†ç ”ç©¶å®éªŒ
        print("\nâ­ [å®éªŒ2] é«˜åˆ†ç ”ç©¶å®éªŒ...")
        high_ratings_study = HighRatingStudy(create_env, exp_name)
        high_ratings_study.run()
        print(f"âœ… [å®éªŒ2] é«˜åˆ†ç ”ç©¶å®éªŒå®Œæˆï¼")
        
        # 3. è¿è¡Œä½åˆ†ç ”ç©¶å®éªŒ
        print("\nğŸ“‰ [å®éªŒ3] ä½åˆ†ç ”ç©¶å®éªŒ...")
        low_ratings_study = LowRatingStudy(create_env, exp_name)
        low_ratings_study.run()
        print(f"âœ… [å®éªŒ3] ä½åˆ†ç ”ç©¶å®éªŒå®Œæˆï¼")
        
        # 4. è¿è¡Œåˆé›†ç ”ç©¶å®éªŒ
        print("\nğŸ“– [å®éªŒ4] åˆé›†ç ”ç©¶å®éªŒ...")
        books_collection_study = BooksCollectionStudy(create_env, exp_name, args.user_dataset)
        books_collection_study.run()
        print(f"âœ… [å®éªŒ4] åˆé›†ç ”ç©¶å®éªŒå®Œæˆï¼")
        
        # 5. è¿è¡Œé‡‡æ ·åˆ†æï¼ˆå¦‚æœä¸è·³è¿‡ï¼‰
        # if not args.skip_sampling:
        #     print("\nğŸ” [å®éªŒ5] é‡‡æ ·åˆ†æå®éªŒ...")
        #     sampling_analysis = SamplingSubsetInteractionsStudy(create_env, exp_name)
        #     sampling_analysis.run()
        #     print(f"âœ… [å®éªŒ5] é‡‡æ ·åˆ†æå®éªŒå®Œæˆï¼")
        # else:
        #     print("\nâ­ï¸ è·³è¿‡é‡‡æ ·åˆ†æå®éªŒ")
        
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼å®éªŒåç§°: {exp_name}")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è¿è¡Œå®éªŒæ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
