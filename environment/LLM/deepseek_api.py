import os
import re
from time import sleep
from typing import Tuple

from .llm import LLM


class DeepSeekModelAPI(LLM):
    def __init__(self, name: str):
        super().__init__(name)
        self.name = name

        # Lazily create client to allow env var setup before first call
        self._client = None

    def _get_client(self):
        if self._client is None:
            # Prefer dedicated DeepSeek env vars; fallback to OpenAI ones for convenience
            api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
            base_url = (
                os.getenv("DEEPSEEK_BASE_URL")
                or os.getenv("OPENAI_BASE_URL")
                or "https://api.deepseek.com"
            )
            # OpenAI 1.x style client
            from openai import OpenAI

            self._client = OpenAI(api_key=api_key, base_url=base_url)
        return self._client

    def _build_messages(self, system_prompt, dialog):
        if system_prompt is None:
            system_prompt = "You are a helpful assistant."
        messages = []
        input_text = ""
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
            input_text += system_prompt
        for d in dialog:
            role = d["role"]
            # å°† assistant_start ä½œä¸ºç”¨æˆ·æŒ‡ä»¤æ³¨å…¥ï¼Œä¿æŒæœ€åä¸€æ¡æ¶ˆæ¯ä¸º userï¼Œåˆ©äºæ¨¡å‹å¯¹é½
            if role == "assistant_start":
                role = "user"
            input_text += "\n" + role + ": "
            input_text += d["content"]
            messages.append({"role": role, "content": d["content"]})
        return input_text, messages

    def _create_chat_completion(self, messages, max_tokens: int, temperature: float = 0.1, top_p: float = 0.9):
        client = self._get_client()
        fail_count = 0
        while True:
            try_again = False
            try:
                resp = client.chat.completions.create(
                    model=self.name,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    timeout=30,  # æ·»åŠ 30ç§’è¶…æ—¶
                )
            except Exception as e:
                print(f"âš ï¸ [DeepSeek] APIè°ƒç”¨å¤±è´¥ (å°è¯• {fail_count + 1}): {e}")
                sleep(10)
                try_again = True
                fail_count += 1
                if fail_count >= 3:  # æœ€å¤šé‡è¯•3æ¬¡
                    print("âŒ [DeepSeek] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé€€å‡º")
                    raise e
            if not try_again:
                return resp

    def request_rating_0_9(self, system_prompt, dialog) -> Tuple[str, str]:
        input_text, messages = self._build_messages(system_prompt, dialog)
        # åªéœ€è¦è¾“å‡ºä¸€ä¸ªæ•°å­—ï¼Œè®¾ç½®è¾ƒå°çš„max_tokens
        out = self._create_chat_completion(messages, max_tokens=5, temperature=0.2, top_p=0.9)
        raw_response = out.choices[0].message.content.strip()
        
        # æ”¹è¿›è§£æé€»è¾‘ï¼šåªåŒ¹é…0-9çš„å•ä¸ªæ•°å­—
        # å¦‚æœå“åº”ä¸­åŒ…å«"10"ç­‰è¶…å‡ºèŒƒå›´çš„æ•°å­—ï¼Œåº”è¯¥è¢«æ‹’ç»
        rating_match = re.search(r'\b([0-9])\b', raw_response)
        if rating_match:
            extracted_rating = rating_match.group(1)
            return input_text, extracted_rating
        else:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¶…å‡ºèŒƒå›´çš„æ•°å­—
            return input_text, "5"  # é»˜è®¤ä¸­ç­‰è¯„åˆ†

    def request_rating_1_10(self, system_prompt, dialog) -> Tuple[str, str]:
        input_text, messages = self._build_messages(system_prompt, dialog)
        # åªéœ€è¦è¾“å‡ºä¸€ä¸ªæ•°å­—ï¼Œè®¾ç½®è¾ƒå°çš„max_tokens
        out = self._create_chat_completion(messages, max_tokens=5, temperature=0.2, top_p=0.9)
        raw_response = out.choices[0].message.content.strip()
        
        # æ”¹è¿›è§£æé€»è¾‘ï¼šæå–ç¬¬ä¸€ä¸ªæ•°å­—1-10
        rating_match = re.search(r'\b(10|[1-9])\b', raw_response)
        if rating_match:
            extracted_rating = rating_match.group(1)
            return input_text, extracted_rating
        else:
            return input_text, "5"  # é»˜è®¤ä¸­ç­‰è¯„åˆ†

    def request_rating_1_5(self, system_prompt, dialog) -> Tuple[str, str]:
        input_text, messages = self._build_messages(system_prompt, dialog)
        
        # æ˜¾ç¤ºå‘é€ç»™APIçš„å®Œæ•´è¯·æ±‚ä¿¡æ¯
        print(f"\nğŸš€ [DeepSeek API] å‘é€è¯„åˆ†è¯·æ±‚ (1-5):")
        print(f"ğŸ“Š æ¨¡å‹: {self.name}")
        print(f"ğŸ“ è¾“å…¥æ–‡æœ¬é•¿åº¦: {len(input_text)} å­—ç¬¦")
        print(f"ğŸ’¬ æ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        # æ˜¾ç¤ºå®Œæ•´çš„è¯·æ±‚å†…å®¹
        print(f"\nğŸ“‹ å‘é€ç»™APIçš„å®Œæ•´å†…å®¹:")
        print("="*80)
        for i, message in enumerate(messages):
            role = message.get("role", "unknown")
            content = message.get("content", "")
            print(f"[{i+1}] {role.upper()}:")
            print(content)
            print("-" * 40)
        print("="*80)
        
        # åªéœ€è¦è¾“å‡ºä¸€ä¸ªæ•°å­—ï¼Œè®¾ç½®è¾ƒå°çš„max_tokens
        out = self._create_chat_completion(messages, max_tokens=5, temperature=0.2, top_p=0.9)
        raw_response = out.choices[0].message.content.strip()
        
        # æ”¹è¿›è§£æé€»è¾‘ï¼šæå–ç¬¬ä¸€ä¸ªæ•°å­—1-5
        rating_match = re.search(r'\b([1-5])\b', raw_response)
        if rating_match:
            extracted_rating = rating_match.group(1)
            return input_text, extracted_rating
        else:
            return input_text, "3"  # é»˜è®¤ä¸­ç­‰è¯„åˆ†

    def request_rating_text(self, system_prompt, dialog) -> Tuple[str, str]:
        input_text, messages = self._build_messages(system_prompt, dialog)
        out = self._create_chat_completion(messages, max_tokens=8, temperature=0.2, top_p=0.9)
        res = out.choices[0].message.content
        return input_text, res

    def query(self, prompt: str) -> str:
        """é€šç”¨æŸ¥è¯¢æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•APIè¿æ¥"""
        messages = [{"role": "user", "content": prompt}]
        try:
            resp = self._create_chat_completion(messages, max_tokens=50, temperature=0.1, top_p=0.9)
            return resp.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ [DeepSeek] æŸ¥è¯¢å¤±è´¥: {e}")
            return f"é”™è¯¯: {e}"

    def request_explanation(self, system_prompt, dialog) -> Tuple[str, str]:
        input_text, messages = self._build_messages(system_prompt, dialog)
        # è°ƒæ•´å‚æ•°ï¼Œç¡®ä¿ç”Ÿæˆç®€æ´ä½†å®Œæ•´çš„è§£é‡Š
        out = self._create_chat_completion(messages, max_tokens=50, temperature=0.5, top_p=0.9)
        res = out.choices[0].message.content
        return input_text, res


